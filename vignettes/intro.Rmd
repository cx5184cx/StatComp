---
title: "Introduction to StatComp20099"
author: "Xiao Chen"
date: "2020-12-19"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp20099}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

__StatComp20099__ is a simple R package developed to compare the performance of R and R++ (implemented through the R package _Rcpp_) for the 'Statistical Computing' course. Two functions are considered, namely, _GNAR_ (generate random nubers using Gibbs sampler) and _Floyd_ . For each function, R versions are produced.



## Introduction of GNAR
Grouped network autoregression(GNAR) model is a simplification of common VAR model with network structure and clusters. GNAR model can be written as:
\begin{equation}
Y_{i t}=\sum_{k=1}^{K} z_{i k}(\beta_{0 k}+\beta_{1 k} n_{i}^{-1} \sum_{j=1}^{N} a_{i j} Y_{j(t-1)}+\beta_{2 k} Y_{i(t-1)}+Z_{i}^{\top} \gamma_k+\sigma_k \varepsilon_{i t}) \label{GNAR1}
\end{equation}
where $z_{i k}\in \{0,1\}$, $z_{i k}=1$ if the $i$th node is from the $k$th group, otherwise $z_{i k}=0$, $\varepsilon_{i t}$ is the independent noise term, and follows standard normal distribution.
To conduct parameter estimation to GNAR model, ordinary least squares(OLS) methods cannot be used since the group label is unknown. So in our package, we use a two-step estimation.  
In the first step, we estimate the coefficient at the nodal level. Secondly, these estimates are pooled together to obtain the parameter estimation $\hat{\theta}_k$ for $k=1,...,K$.  
In this section, we use the form \eqref{GNAR2} of the GNAR model to estimate the parameters. We let $\mathbf{b}_i=(b_{0 i}+V_i^{\top}\gamma_i,b_{1 i},b_{2 i})^{\top}\in \mathbb{R}^3$ and $\mathbf{X}_{i t}=
(1,\omega_i^{\top} \mathbb{Y}_t,Y_{i t})\in \mathbb{R}^3$. Then the estimate of $\mathbf{b}_i$ can be obtained as
\begin{equation}
\hat{\mathbf{b}}_i=\left(\sum_{t=1}^T \mathbf{X}_{i (t-1)} \mathbf{X}_{i (t-1)}^{\top}\right)^{-1} \left(\sum_{t=1}^T \mathbf{X}_{i (t-1)}Y_{i t}\right)     \label{two step}
\end{equation}
We can see that \eqref{two step} is the ordinary least squares estimation for each node. And from \citet{Zhu and Pan:2018}, they prove that when $T$ is sufficiently large, the estimate will approximate the true value.   
Since the approximating of the estimate, we consider the  second step for estimation. The nodes are divided into K groups and let the members of the $k$th group are collected in $\widehat{M}_k$, and $\widehat{N}_k=\left| \widehat{M}_k\right|$ is the number of members of the $k$th group. After obtaining $\widehat{N}_k$, we can directly estimate the group ratio $\alpha_k$ by $\hat{\alpha}_k=\widehat{N}_k/N$.   
In a word, when the estimated group information is given, we can easily estimate the parameters by using the OLS estimation. the estimation of $\theta_k$ can be written as
\begin{equation}
\hat{\theta}_k^{TS}=\left(\sum_{t=1}^T\sum_{i\in \widehat{M}_k} X_{i (t-1)}X_{i (t-1)}^{\top}\right)^{-1}\left(\sum_{t=1}^T\sum_{i\in \widehat{M}_k} X_{i (t-1)}Y_{i t}\right)
\end{equation}
which is referred to as the two step (TS) estimator.  
After that, we can use the GNAR package to forecast the real data. Here we give a case of S\&P500 containers forecast using GNAR package.
```{r GNAR}
library(StatComp20099)
library(MASS)
library(plyr)
require(methods)
require(quantmod)
require(tseries)
require(lmtest)
library(vars)
library(forecast)
library(tseries)
options(warn=-1)
GNAR<-function(A,Z,data,begin,end,K,t)
{       
  ### Two step estimation
  Cluster.NAR<-function(Ymat, W,  Z, K, method = "complete",  group = NULL)
  {
    N = nrow(Ymat)
    Time = ncol(Ymat)
    Ymat1 = W%*%Ymat     
    ### 求得回顾数据集
    if (is.null(Z))
      yy_dat = data.frame(id = rep(1:N, each = Time - 1),
                          inter = 1,
                          net = as.vector(t(Ymat1[,-ncol(Ymat)])),
                          lagY = as.vector(t(Ymat[,-ncol(Ymat)])),
                          Y = as.vector(t(Ymat[,-1]))) 
    else
      yy_dat = data.frame(id = rep(1:N, each = Time - 1),
                          inter = 1,
                          net = as.vector(t(Ymat1[,-ncol(Ymat)])),
                          lagY = as.vector(t(Ymat[,-ncol(Ymat)])),
                          Z[rep(1:N, each = Time-1),],
                          Y = as.vector(t(Ymat[,-1])))
    
    ### 对每个节点求b_i估计值
    paras = ddply(yy_dat, .(id), function(x){
      X = as.matrix(x[,2:4])
      invXX = ginv(crossprod(X))                                                                                   ### the response vector
      thetaEst = invXX%*%colSums(X*x$Y)   
      df = data.frame(matrix(c(thetaEst), nrow = 1))
    })
    
    colnames(paras)[-1] = c("intercept", "network", "momentum")
    
    ### 规范化网络和动量参数并计算节点的距离
    para_scale = apply(paras[,3:4], 2, function(x) x/max(abs(x)))#scale(paras[,3:4])
    para_dist = dist(as.matrix(para_scale))
    
    ### 实施聚类算法
    if (method=="kmeans")
    {
      #nar_para = betaOLS(Ymat, W, Z)
      #ini_theta = (sapply(nar_para$theta[2:3], function(x) runif(K, min = x-0.05, max = x+0.05)))
      k_res = kmeans(para_scale, K)
      memb = k_res$cluster
    }
    else
    {
      hcl = hclust(para_dist, method = method)
      memb = cutree(hcl, k = K)
    }
    alpha = table(memb)/length(memb)
    yy_dat$group = rep(memb, each = Time - 1) # 求得不同节点的组
    ### 对每个组重新进行估计
    theta_est = ddply(yy_dat, .(group), function(x){
      X = as.matrix(x[,2:(ncol(x)-2)])
      invXX = ginv(crossprod(X))                                                                                   ### the response vector
      thetaEst = invXX%*%colSums(X*x$Y)   
      df = data.frame(matrix(c(thetaEst), nrow = 1))
    })
    return(list(theta = t(theta_est)[-1,], alpha = alpha, group = memb))
  }
  N=length(data)
  L=end-begin+1
  data1=matrix(0,nrow=N,ncol=L)
  for(i in 1:N) data1[i,]=data[[i]][begin:end]
  for(j in 1:t) data1=cbind(data1,0)
  W=A/rowSums(A)
  W[is.na(W)]=0
  Z=as.matrix(Z)
  cl_res = Cluster.NAR(data1, W, Z, K, method = "complete") # two-step estimation
  theta=cl_res$theta
  group=cl_res$group
  D=NULL
  before=NULL  #最后一个数据的值
  prob=NULL
  forecast=matrix(0,nrow=N,ncol=t)  #预测值
  real=matrix(0,nrow=N,ncol=t)  #真实值
  D=matrix(0,nrow=N,ncol=t)     #是否正确 
  for(i in 1:N)before[i]=exp(data[[i]][end])
  for(j in 1:t){
    Ymat=data1[,1:(L+j-1)]
    WYmat = W%*%Ymat
    N = nrow(Ymat)
    Time = ncol(Ymat)
    if (is.null(Z))
      X = cbind(1, lagWY = as.vector(WYmat), lagY = as.vector(Ymat))
    else
      X = cbind(1, lagWY = as.vector(WYmat), lagY = as.vector(Ymat),
                do.call(rbind, rep(list(Z), Time)))
    Yhat = matrix((X%*%theta)[cbind(1:nrow(X), rep(group, Time))], nrow = N)
    data1[,L+j]=Yhat[,L+j-1]
  }
  for(j in 1:t)  forecast[,j]=data1[,L+j]
  for(j in 1:t){
    for(i in 1:N){
      real[i,j]=exp(data[[i]][end+j])
      if((real[i,j]-before[i])*(forecast[i,j]-before[i])>0)
        D[i,j]=1
      if((real[i,j]-before[i])*(forecast[i,j]-before[i])<=0)
        D[i,j]=0
    }
    prob[j]=sum(D[,j])/length(D[,j])
  }
  M=cbind(before,real,forecast,D)
  colnames(M)=c("before",rep("real",t),rep("forecast",t),rep("D",t))
  rownames(M)=names(A[,1])
  return(list(M,prob))
}
data(A)
data(Z)
data(data)
M = GNAR(A,Z,data,1,503,2,10)
plot(M[[2]],type='b',ylim=c(0.35,0.6),col='red',lwd=2, xlab="days",ylab="accuracy",pch=1)
```


## Floyd
To solve the shortest path problem, Floyd algorithm is a common method. The key is to loop to find the shortest path between two spots. The algorithm is
\begin{equation}
map[i,j]= \min{map[i,k]+map[k,j], map[i,j]}.
\end{equation}
In our package, we will give the function to find the shortest path using Floyd algorithm and the least cost and the shortest path between each two spots will be given.
```{r Floyd}
floyd<-function(A){
  A[A==0]<-Inf
  n<-nrow(A)
  D<-A
  path<-matrix(0,n,n)
  for(i in 1:n){
    for(j in 1:n){
      if(is.finite(D[i,j])==T){path[i,j]=j}
    }
  }
  for(k in 1:n){
    for(i in 1:n){
      for(j in 1:n){
        if(D[i,k]+D[k,j]<D[i,j]){
          D[i,j]=D[i,k]+D[k,j];
          path[i,j]=path[i,k]
        }
      }
    }
  }
  return(list(D=D,path=path))
}
a<-matrix(0,7,7)
a[1,2]=3;a[1,3]=5; a[2,3]=1;a[2,4]=5;a[2,5]=8
a[3,4]=7;a[3,5]=4;a[3,6]=10; a[4,5]=3;a[4,7]=6
a[5,6]=1;a[5,7]=2; a[6,7]=2
b<-a+t(a)
floyd(b)
```
